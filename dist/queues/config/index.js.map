{"version":3,"sources":["../../../src/queues/config/index.ts"],"sourcesContent":["import type { CollectionConfig } from '../../collections/config/types.js'\nimport type { Config, SanitizedConfig } from '../../config/types.js'\nimport type { Field } from '../../fields/config/types.js'\nimport type { BaseJob } from './types/workflowTypes.js'\n\nimport { runJobsEndpoint } from '../restEndpointRun.js'\nimport { getJobTaskStatus } from '../utilities/getJobTaskStatus.js'\n\nexport const jobsCollectionSlug = 'payload-jobs'\n\nexport const getDefaultJobsCollection: (config: Config) => CollectionConfig | null = (config) => {\n  const workflowSlugs: Set<string> = new Set()\n  const taskSlugs: Set<string> = new Set(['inline'])\n\n  if (config.jobs?.workflows?.length) {\n    config.jobs?.workflows.forEach((workflow) => {\n      workflowSlugs.add(workflow.slug)\n    })\n  }\n\n  if (config.jobs?.tasks?.length) {\n    config.jobs.tasks.forEach((task) => {\n      if (workflowSlugs.has(task.slug)) {\n        throw new Error(\n          `Task slug \"${task.slug}\" is already used by a workflow. No tasks are allowed to have the same slug as a workflow.`,\n        )\n      }\n      taskSlugs.add(task.slug)\n    })\n  }\n\n  const logFields: Field[] = [\n    {\n      name: 'executedAt',\n      type: 'date',\n      required: true,\n    },\n    {\n      name: 'completedAt',\n      type: 'date',\n      required: true,\n    },\n    {\n      name: 'taskSlug',\n      type: 'select',\n      options: [...taskSlugs],\n      required: true,\n    },\n    {\n      name: 'taskID',\n      type: 'text',\n      required: true,\n    },\n    {\n      name: 'input',\n      type: 'json',\n    },\n    {\n      name: 'output',\n      type: 'json',\n    },\n    {\n      name: 'state',\n      type: 'radio',\n      options: ['failed', 'succeeded'],\n      required: true,\n    },\n    {\n      name: 'error',\n      type: 'json',\n      admin: {\n        condition: (_, data) => data.state === 'failed',\n      },\n      required: true,\n    },\n  ]\n\n  if (config?.jobs?.addParentToTaskLog) {\n    logFields.push({\n      name: 'parent',\n      type: 'group',\n      fields: [\n        {\n          name: 'taskSlug',\n          type: 'select',\n          options: [...taskSlugs],\n        },\n        {\n          name: 'taskID',\n          type: 'text',\n        },\n      ],\n    })\n  }\n\n  const jobsCollection: CollectionConfig = {\n    slug: jobsCollectionSlug,\n    admin: {\n      group: 'System',\n      hidden: true,\n    },\n    endpoints: [runJobsEndpoint],\n    fields: [\n      {\n        name: 'input',\n        type: 'json',\n        admin: {\n          description: 'Input data provided to the job',\n        },\n      },\n      {\n        name: 'taskStatus',\n        type: 'json',\n        virtual: true,\n      },\n      {\n        type: 'tabs',\n        tabs: [\n          {\n            fields: [\n              {\n                name: 'completedAt',\n                type: 'date',\n                index: true,\n              },\n              {\n                name: 'totalTried',\n                type: 'number',\n                defaultValue: 0,\n                index: true,\n              },\n              {\n                name: 'hasError',\n                type: 'checkbox',\n                admin: {\n                  description: 'If hasError is true this job will not be retried',\n                },\n                defaultValue: false,\n                index: true,\n              },\n              {\n                name: 'error',\n                type: 'json',\n                admin: {\n                  condition: (data) => data.hasError,\n                  description: 'If hasError is true, this is the error that caused it',\n                },\n              },\n              {\n                name: 'log',\n                type: 'array',\n                admin: {\n                  description: 'Task execution log',\n                },\n                fields: logFields,\n              },\n            ],\n            label: 'Status',\n          },\n        ],\n      },\n      // only include the workflowSlugs field if workflows exist\n      ...((workflowSlugs.size > 0\n        ? [\n            {\n              name: 'workflowSlug',\n              type: 'select',\n              admin: {\n                position: 'sidebar',\n              },\n              index: true,\n              options: [...workflowSlugs],\n            },\n          ]\n        : []) as Field[]),\n      {\n        name: 'taskSlug',\n        type: 'select',\n        admin: {\n          position: 'sidebar',\n        },\n        index: true,\n        options: [...taskSlugs],\n        required: false,\n      },\n      {\n        name: 'queue',\n        type: 'text',\n        admin: {\n          position: 'sidebar',\n        },\n        defaultValue: 'default',\n        index: true,\n      },\n      {\n        name: 'waitUntil',\n        type: 'date',\n        index: true,\n      },\n      {\n        name: 'processing',\n        type: 'checkbox',\n        admin: {\n          position: 'sidebar',\n        },\n        defaultValue: false,\n        index: true,\n      },\n    ],\n    hooks: {\n      afterRead: [\n        ({ doc, req }) => {\n          // This hook is used to add the virtual `tasks` field to the document, that is computed from the `log` field\n\n          return jobAfterRead({ config: req.payload.config, doc })\n        },\n      ],\n      /**\n       * If another update comes in after a job as already been cancelled, we need to make sure that update doesn't\n       * change the state of the job.\n       */\n      beforeChange: [\n        ({ data, originalDoc }) => {\n          if (originalDoc?.error?.cancelled) {\n            data.processing = false\n            data.hasError = true\n            delete data.completedAt\n            delete data.waitUntil\n          }\n          return data\n        },\n      ],\n    },\n    lockDocuments: false,\n  }\n\n  return jobsCollection\n}\n\nexport function jobAfterRead({ config, doc }: { config: SanitizedConfig; doc: BaseJob }): BaseJob {\n  doc.taskStatus = getJobTaskStatus({\n    jobLog: doc.log || [],\n  })\n  return doc\n}\n"],"names":["runJobsEndpoint","getJobTaskStatus","jobsCollectionSlug","getDefaultJobsCollection","config","workflowSlugs","Set","taskSlugs","jobs","workflows","length","forEach","workflow","add","slug","tasks","task","has","Error","logFields","name","type","required","options","admin","condition","_","data","state","addParentToTaskLog","push","fields","jobsCollection","group","hidden","endpoints","description","virtual","tabs","index","defaultValue","hasError","label","size","position","hooks","afterRead","doc","req","jobAfterRead","payload","beforeChange","originalDoc","error","cancelled","processing","completedAt","waitUntil","lockDocuments","taskStatus","jobLog","log"],"mappings":"AAKA,SAASA,eAAe,QAAQ,wBAAuB;AACvD,SAASC,gBAAgB,QAAQ,mCAAkC;AAEnE,OAAO,MAAMC,qBAAqB,eAAc;AAEhD,OAAO,MAAMC,2BAAwE,CAACC;IACpF,MAAMC,gBAA6B,IAAIC;IACvC,MAAMC,YAAyB,IAAID,IAAI;QAAC;KAAS;IAEjD,IAAIF,OAAOI,IAAI,EAAEC,WAAWC,QAAQ;QAClCN,OAAOI,IAAI,EAAEC,UAAUE,QAAQ,CAACC;YAC9BP,cAAcQ,GAAG,CAACD,SAASE,IAAI;QACjC;IACF;IAEA,IAAIV,OAAOI,IAAI,EAAEO,OAAOL,QAAQ;QAC9BN,OAAOI,IAAI,CAACO,KAAK,CAACJ,OAAO,CAAC,CAACK;YACzB,IAAIX,cAAcY,GAAG,CAACD,KAAKF,IAAI,GAAG;gBAChC,MAAM,IAAII,MACR,CAAC,WAAW,EAAEF,KAAKF,IAAI,CAAC,0FAA0F,CAAC;YAEvH;YACAP,UAAUM,GAAG,CAACG,KAAKF,IAAI;QACzB;IACF;IAEA,MAAMK,YAAqB;QACzB;YACEC,MAAM;YACNC,MAAM;YACNC,UAAU;QACZ;QACA;YACEF,MAAM;YACNC,MAAM;YACNC,UAAU;QACZ;QACA;YACEF,MAAM;YACNC,MAAM;YACNE,SAAS;mBAAIhB;aAAU;YACvBe,UAAU;QACZ;QACA;YACEF,MAAM;YACNC,MAAM;YACNC,UAAU;QACZ;QACA;YACEF,MAAM;YACNC,MAAM;QACR;QACA;YACED,MAAM;YACNC,MAAM;QACR;QACA;YACED,MAAM;YACNC,MAAM;YACNE,SAAS;gBAAC;gBAAU;aAAY;YAChCD,UAAU;QACZ;QACA;YACEF,MAAM;YACNC,MAAM;YACNG,OAAO;gBACLC,WAAW,CAACC,GAAGC,OAASA,KAAKC,KAAK,KAAK;YACzC;YACAN,UAAU;QACZ;KACD;IAED,IAAIlB,QAAQI,MAAMqB,oBAAoB;QACpCV,UAAUW,IAAI,CAAC;YACbV,MAAM;YACNC,MAAM;YACNU,QAAQ;gBACN;oBACEX,MAAM;oBACNC,MAAM;oBACNE,SAAS;2BAAIhB;qBAAU;gBACzB;gBACA;oBACEa,MAAM;oBACNC,MAAM;gBACR;aACD;QACH;IACF;IAEA,MAAMW,iBAAmC;QACvClB,MAAMZ;QACNsB,OAAO;YACLS,OAAO;YACPC,QAAQ;QACV;QACAC,WAAW;YAACnC;SAAgB;QAC5B+B,QAAQ;YACN;gBACEX,MAAM;gBACNC,MAAM;gBACNG,OAAO;oBACLY,aAAa;gBACf;YACF;YACA;gBACEhB,MAAM;gBACNC,MAAM;gBACNgB,SAAS;YACX;YACA;gBACEhB,MAAM;gBACNiB,MAAM;oBACJ;wBACEP,QAAQ;4BACN;gCACEX,MAAM;gCACNC,MAAM;gCACNkB,OAAO;4BACT;4BACA;gCACEnB,MAAM;gCACNC,MAAM;gCACNmB,cAAc;gCACdD,OAAO;4BACT;4BACA;gCACEnB,MAAM;gCACNC,MAAM;gCACNG,OAAO;oCACLY,aAAa;gCACf;gCACAI,cAAc;gCACdD,OAAO;4BACT;4BACA;gCACEnB,MAAM;gCACNC,MAAM;gCACNG,OAAO;oCACLC,WAAW,CAACE,OAASA,KAAKc,QAAQ;oCAClCL,aAAa;gCACf;4BACF;4BACA;gCACEhB,MAAM;gCACNC,MAAM;gCACNG,OAAO;oCACLY,aAAa;gCACf;gCACAL,QAAQZ;4BACV;yBACD;wBACDuB,OAAO;oBACT;iBACD;YACH;YACA,0DAA0D;eACrDrC,cAAcsC,IAAI,GAAG,IACtB;gBACE;oBACEvB,MAAM;oBACNC,MAAM;oBACNG,OAAO;wBACLoB,UAAU;oBACZ;oBACAL,OAAO;oBACPhB,SAAS;2BAAIlB;qBAAc;gBAC7B;aACD,GACD,EAAE;YACN;gBACEe,MAAM;gBACNC,MAAM;gBACNG,OAAO;oBACLoB,UAAU;gBACZ;gBACAL,OAAO;gBACPhB,SAAS;uBAAIhB;iBAAU;gBACvBe,UAAU;YACZ;YACA;gBACEF,MAAM;gBACNC,MAAM;gBACNG,OAAO;oBACLoB,UAAU;gBACZ;gBACAJ,cAAc;gBACdD,OAAO;YACT;YACA;gBACEnB,MAAM;gBACNC,MAAM;gBACNkB,OAAO;YACT;YACA;gBACEnB,MAAM;gBACNC,MAAM;gBACNG,OAAO;oBACLoB,UAAU;gBACZ;gBACAJ,cAAc;gBACdD,OAAO;YACT;SACD;QACDM,OAAO;YACLC,WAAW;gBACT,CAAC,EAAEC,GAAG,EAAEC,GAAG,EAAE;oBACX,4GAA4G;oBAE5G,OAAOC,aAAa;wBAAE7C,QAAQ4C,IAAIE,OAAO,CAAC9C,MAAM;wBAAE2C;oBAAI;gBACxD;aACD;YACD;;;OAGC,GACDI,cAAc;gBACZ,CAAC,EAAExB,IAAI,EAAEyB,WAAW,EAAE;oBACpB,IAAIA,aAAaC,OAAOC,WAAW;wBACjC3B,KAAK4B,UAAU,GAAG;wBAClB5B,KAAKc,QAAQ,GAAG;wBAChB,OAAOd,KAAK6B,WAAW;wBACvB,OAAO7B,KAAK8B,SAAS;oBACvB;oBACA,OAAO9B;gBACT;aACD;QACH;QACA+B,eAAe;IACjB;IAEA,OAAO1B;AACT,EAAC;AAED,OAAO,SAASiB,aAAa,EAAE7C,MAAM,EAAE2C,GAAG,EAA6C;IACrFA,IAAIY,UAAU,GAAG1D,iBAAiB;QAChC2D,QAAQb,IAAIc,GAAG,IAAI,EAAE;IACvB;IACA,OAAOd;AACT"}