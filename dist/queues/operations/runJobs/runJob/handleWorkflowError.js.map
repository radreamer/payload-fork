{"version":3,"sources":["../../../../../src/queues/operations/runJobs/runJob/handleWorkflowError.ts"],"sourcesContent":["// @ts-strict-ignore\nimport type { PayloadRequest } from '../../../../types/index.js'\nimport type { BaseJob, WorkflowConfig, WorkflowTypes } from '../../../config/types/workflowTypes.js'\nimport type { RunTaskFunctionState } from './getRunTaskFunction.js'\n\nimport { calculateBackoffWaitUntil } from './calculateBackoffWaitUntil.js'\n\n/**\n * This is called if a workflow catches an error. It determines if it's a final error\n * or not and handles logging.\n */\nexport function handleWorkflowError({\n  error,\n  job,\n  req,\n  state,\n  workflowConfig,\n}: {\n  error: Error\n  job: BaseJob\n  req: PayloadRequest\n  state: RunTaskFunctionState\n  workflowConfig: WorkflowConfig<WorkflowTypes>\n}): {\n  hasFinalError: boolean\n} {\n  const jobLabel = job.workflowSlug || `Task: ${job.taskSlug}`\n\n  let hasFinalError = state.reachedMaxRetries || !!('cancelled' in error && error.cancelled) // If any TASK reached max retries, the job has an error\n  const maxWorkflowRetries: number =\n    (typeof workflowConfig.retries === 'object'\n      ? workflowConfig.retries.attempts\n      : workflowConfig.retries) ?? undefined\n\n  if (\n    maxWorkflowRetries !== undefined &&\n    maxWorkflowRetries !== null &&\n    job.totalTried >= maxWorkflowRetries\n  ) {\n    hasFinalError = true\n    state.reachedMaxRetries = true\n  }\n\n  // Now let's handle workflow retries\n  if (!hasFinalError) {\n    if (job.waitUntil) {\n      // Check if waitUntil is in the past\n      const waitUntil = new Date(job.waitUntil)\n      if (waitUntil < new Date()) {\n        // Outdated waitUntil, remove it\n        delete job.waitUntil\n      }\n    }\n\n    // Job will retry. Let's determine when!\n    const waitUntil: Date = calculateBackoffWaitUntil({\n      retriesConfig: workflowConfig.retries,\n      totalTried: job.totalTried ?? 0,\n    })\n\n    // Update job's waitUntil only if this waitUntil is later than the current one\n    if (!job.waitUntil || waitUntil > new Date(job.waitUntil)) {\n      job.waitUntil = waitUntil.toISOString()\n    }\n  }\n\n  req.payload.logger.error({\n    err: error,\n    msg: `Error running job ${jobLabel} id: ${job.id} attempt ${job.totalTried + 1}${maxWorkflowRetries !== undefined ? '/' + (maxWorkflowRetries + 1) : ''}`,\n  })\n\n  return {\n    hasFinalError,\n  }\n}\n"],"names":["calculateBackoffWaitUntil","handleWorkflowError","error","job","req","state","workflowConfig","jobLabel","workflowSlug","taskSlug","hasFinalError","reachedMaxRetries","cancelled","maxWorkflowRetries","retries","attempts","undefined","totalTried","waitUntil","Date","retriesConfig","toISOString","payload","logger","err","msg","id"],"mappings":"AAAA,oBAAoB;AAKpB,SAASA,yBAAyB,QAAQ,iCAAgC;AAE1E;;;CAGC,GACD,OAAO,SAASC,oBAAoB,EAClCC,KAAK,EACLC,GAAG,EACHC,GAAG,EACHC,KAAK,EACLC,cAAc,EAOf;IAGC,MAAMC,WAAWJ,IAAIK,YAAY,IAAI,CAAC,MAAM,EAAEL,IAAIM,QAAQ,EAAE;IAE5D,IAAIC,gBAAgBL,MAAMM,iBAAiB,IAAI,CAAC,CAAE,CAAA,eAAeT,SAASA,MAAMU,SAAS,CAAE,wDAAwD;IAA3D;IACxF,MAAMC,qBACJ,AAAC,CAAA,OAAOP,eAAeQ,OAAO,KAAK,WAC/BR,eAAeQ,OAAO,CAACC,QAAQ,GAC/BT,eAAeQ,OAAO,AAAD,KAAME;IAEjC,IACEH,uBAAuBG,aACvBH,uBAAuB,QACvBV,IAAIc,UAAU,IAAIJ,oBAClB;QACAH,gBAAgB;QAChBL,MAAMM,iBAAiB,GAAG;IAC5B;IAEA,oCAAoC;IACpC,IAAI,CAACD,eAAe;QAClB,IAAIP,IAAIe,SAAS,EAAE;YACjB,oCAAoC;YACpC,MAAMA,YAAY,IAAIC,KAAKhB,IAAIe,SAAS;YACxC,IAAIA,YAAY,IAAIC,QAAQ;gBAC1B,gCAAgC;gBAChC,OAAOhB,IAAIe,SAAS;YACtB;QACF;QAEA,wCAAwC;QACxC,MAAMA,YAAkBlB,0BAA0B;YAChDoB,eAAed,eAAeQ,OAAO;YACrCG,YAAYd,IAAIc,UAAU,IAAI;QAChC;QAEA,8EAA8E;QAC9E,IAAI,CAACd,IAAIe,SAAS,IAAIA,YAAY,IAAIC,KAAKhB,IAAIe,SAAS,GAAG;YACzDf,IAAIe,SAAS,GAAGA,UAAUG,WAAW;QACvC;IACF;IAEAjB,IAAIkB,OAAO,CAACC,MAAM,CAACrB,KAAK,CAAC;QACvBsB,KAAKtB;QACLuB,KAAK,CAAC,kBAAkB,EAAElB,SAAS,KAAK,EAAEJ,IAAIuB,EAAE,CAAC,SAAS,EAAEvB,IAAIc,UAAU,GAAG,IAAIJ,uBAAuBG,YAAY,MAAOH,CAAAA,qBAAqB,CAAA,IAAK,IAAI;IAC3J;IAEA,OAAO;QACLH;IACF;AACF"}